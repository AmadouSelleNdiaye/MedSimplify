{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bd9309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"cbasu/Med-EASi\", split=\"train\")\n",
    "sources = dataset[\"Expert\"]\n",
    "references = dataset[\"Simple\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f016ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLUE (n-gram 1 to 4, geometric mean + brevity penalty)\n",
    "def n_gram_precision(pred, ref, n):\n",
    "    pred_ngrams = Counter([tuple(pred[i:i+n]) for i in range(len(pred)-n+1)])\n",
    "    ref_ngrams = Counter([tuple(ref[i:i+n]) for i in range(len(ref)-n+1)])\n",
    "    overlap = sum((pred_ngrams & ref_ngrams).values())\n",
    "    total = max(sum(pred_ngrams.values()), 1)\n",
    "    return overlap / total\n",
    "\n",
    "def compute_bleu(pred, ref):\n",
    "    pred = pred.split()\n",
    "    ref = ref.split()\n",
    "    precisions = [n_gram_precision(pred, ref, n) for n in range(1, 5)]\n",
    "    if all(p == 0 for p in precisions):\n",
    "        bleu = 0\n",
    "    else:\n",
    "        score = np.exp(np.mean([np.log(p + 1e-9) for p in precisions]))\n",
    "        bp = np.exp(1 - len(ref)/len(pred)) if len(pred) < len(ref) else 1\n",
    "        bleu = bp * score\n",
    "    return bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fa1e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUGE-L (LCS-basiert F1)\n",
    "def lcs(X, Y):\n",
    "    m, n = len(X), len(Y)\n",
    "    L = [[0]*(n+1) for _ in range(m+1)]\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if X[i] == Y[j]:\n",
    "                L[i+1][j+1] = L[i][j] + 1\n",
    "            else:\n",
    "                L[i+1][j+1] = max(L[i+1][j], L[i][j+1])\n",
    "    return L[m][n]\n",
    "\n",
    "def compute_rouge_l(pred, ref):\n",
    "    pred_tokens, ref_tokens = pred.split(), ref.split()\n",
    "    lcs_len = lcs(pred_tokens, ref_tokens)\n",
    "    prec = lcs_len / max(len(pred_tokens), 1)\n",
    "    rec = lcs_len / max(len(ref_tokens), 1)\n",
    "    if prec + rec == 0:\n",
    "        return 0\n",
    "    return 2 * prec * rec / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c2d11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARI (Add, Keep, Delete F1 over n-grams)\n",
    "def ngrams(s, n):\n",
    "    return set([' '.join(s[i:i+n]) for i in range(len(s)-n+1)])\n",
    "\n",
    "def compute_sari(source, pred, ref):\n",
    "    source_tokens = source.split()\n",
    "    pred_tokens = pred.split()\n",
    "    ref_tokens = ref.split()\n",
    "    score_add, score_keep, score_del = [], [], []\n",
    "\n",
    "    for n in range(1, 5):\n",
    "        S = ngrams(source_tokens, n)\n",
    "        P = ngrams(pred_tokens, n) \n",
    "        R = ngrams(ref_tokens, n)\n",
    "\n",
    "        add = P - S\n",
    "        keep = P & S\n",
    "        del_ = S - P\n",
    "\n",
    "        add_prec = len(add & R) / max(len(add), 1)\n",
    "        add_rec = len(add & R) / max(len(R - S), 1)\n",
    "        f1_add = 2 * add_prec * add_rec / (add_prec + add_rec + 1e-9)\n",
    "\n",
    "        keep_prec = len(keep & R) / max(len(keep), 1)\n",
    "        keep_rec = len(keep & R) / max(len(S & R), 1)\n",
    "        f1_keep = 2 * keep_prec * keep_rec / (keep_prec + keep_rec + 1e-9)\n",
    "\n",
    "        del_prec = len(del_ - R) / max(len(del_), 1)\n",
    "        del_rec = len(del_ - R) / max(len(S - R), 1)\n",
    "        f1_del = 2 * del_prec * del_rec / (del_prec + del_rec + 1e-9)\n",
    "\n",
    "        score_add.append(f1_add)\n",
    "        score_keep.append(f1_keep)\n",
    "        score_del.append(f1_del)\n",
    "\n",
    "    return (np.mean(score_add) + np.mean(score_keep) + np.mean(score_del)) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b41ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU moyenne: 0.35291779495439884\n",
      "ROUGE-L moyenne: 0.562452054529192\n",
      "SARI moyenne : 0.9382009062357433\n"
     ]
    }
   ],
   "source": [
    "# Calculating scores for the whole set\n",
    "bleu_scores = []\n",
    "rouge_scores = []\n",
    "sari_scores = []\n",
    "\n",
    "for src, ref in zip(sources, references):\n",
    "    bleu_scores.append(compute_bleu(ref, src))\n",
    "    rouge_scores.append(compute_rouge_l(ref, src))\n",
    "    sari_scores.append(compute_sari(src, ref, ref))\n",
    "\n",
    "print(\"BLEU moyenne:\", np.mean(bleu_scores))\n",
    "print(\"ROUGE-L moyenne:\", np.mean(rouge_scores))\n",
    "print(\"SARI moyenne :\", np.mean(sari_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medsimpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
